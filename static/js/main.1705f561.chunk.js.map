{"version":3,"sources":["App.js","reportWebVitals.js","index.js"],"names":["App","videoRef","React","createRef","canvasRef","styles","position","top","left","detectFromVideoFrame","model","video","detect","then","predictions","showDetections","requestAnimationFrame","error","console","log","ctx","current","getContext","clearRect","canvas","width","height","font","textBaseline","forEach","prediction","x","bbox","y","strokeStyle","lineWidth","strokeRect","fillStyle","textWidth","measureText","class","textHeight","parseInt","fillRect","fillText","score","toFixed","navigator","mediaDevices","getUserMedia","webkitGetUserMedia","webcamPromise","audio","stream","window","srcObject","Promise","resolve","onloadedmetadata","loadlModelPromise","cocoSsd","all","values","catch","style","this","autoPlay","muted","playsInline","ref","Component","domContainer","document","querySelector","ReactDOM","render","createElement","reportWebVitals","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","StrictMode","getElementById"],"mappings":"sVAOMA,G,mNAEJC,SAAWC,IAAMC,Y,EACjBC,UAAYF,IAAMC,Y,EAGlBE,OAAS,CACPC,SAAU,QACVC,IAAK,IACLC,KAAM,K,EAIRC,qBAAuB,SAACC,EAAOC,GAC7BD,EAAME,OAAOD,GAAOE,MAAK,SAAAC,GACvB,EAAKC,eAAeD,GAEpBE,uBAAsB,WACpB,EAAKP,qBAAqBC,EAAOC,SAElC,SAACM,GACFC,QAAQC,IAAI,6BACZD,QAAQD,MAAMA,O,EAIlBF,eAAiB,SAAAD,GACf,IAAMM,EAAM,EAAKhB,UAAUiB,QAAQC,WAAW,MAC9CF,EAAIG,UAAU,EAAG,EAAGH,EAAII,OAAOC,MAAOL,EAAII,OAAOE,QACjD,IAAMC,EAAO,iBACbP,EAAIO,KAAOA,EACXP,EAAIQ,aAAe,MAEnBd,EAAYe,SAAQ,SAAAC,GAClB,IAAMC,EAAID,EAAWE,KAAK,GACpBC,EAAIH,EAAWE,KAAK,GACpBP,EAAQK,EAAWE,KAAK,GACxBN,EAASI,EAAWE,KAAK,GAE/BZ,EAAIc,YAAc,UAClBd,EAAIe,UAAY,EAChBf,EAAIgB,WAAWL,EAAGE,EAAGR,EAAOC,GAE5BN,EAAIiB,UAAY,UAChB,IAAMC,EAAYlB,EAAImB,YAAYT,EAAWU,OAAOf,MAC9CgB,EAAaC,SAASf,EAAM,IAElCP,EAAIuB,SAASZ,EAAGE,EAAGK,EAAY,GAAIG,EAAa,IAEhDrB,EAAIuB,SAASZ,EAAGE,EAAIP,EAASe,EAAYH,EAAY,GAAIG,EAAa,IAGtErB,EAAIiB,UAAY,UAChBjB,EAAIwB,SAASd,EAAWU,MAAOT,EAAGE,GAClCb,EAAIwB,SAASd,EAAWe,MAAMC,QAAQ,GAAIf,EAAGE,EAAIP,EAASe,O,kEAIzC,IAAD,OAClB,GAAIM,UAAUC,aAAaC,cAAgBF,UAAUC,aAAaE,mBAAoB,CAEpF,IAAMC,EAAgBJ,UAAUC,aAC7BC,aAAa,CACZtC,OAAO,EACPyC,OAAO,IAERvC,MAAK,SAAAwC,GAMJ,OAJAC,OAAOD,OAASA,EAEhB,EAAKpD,SAASoB,QAAQkC,UAAYF,EAE3B,IAAIG,SAAQ,SAAAC,GACjB,EAAKxD,SAASoB,QAAQqC,iBAAmB,WACvCD,WAGH,SAACxC,GACFC,QAAQC,IAAI,6BACZD,QAAQD,MAAMA,MAIZ0C,EAAoBC,SAG1BJ,QAAQK,IAAI,CAACF,EAAmBR,IAC7BtC,MAAK,SAAAiD,GACJ,EAAKrD,qBAAqBqD,EAAO,GAAI,EAAK7D,SAASoB,YAEpD0C,OAAM,SAAA9C,GACLC,QAAQD,MAAMA,S,+BAQpB,OACE,gCACE,uBACE+C,MAAOC,KAAK5D,OACZ6D,UAAQ,EACRC,OAAK,EACLC,aAAW,EACXC,IAAKJ,KAAKhE,SACVwB,MAAM,MACNC,OAAO,QAET,wBAAQsC,MAAOC,KAAK5D,OAAQgE,IAAKJ,KAAK7D,UAAWqB,MAAM,MAAMC,OAAO,e,GA9G1DxB,IAAMoE,YAoHTtE,IACTuE,EAAeC,SAASC,cAAc,SAC5CC,IAASC,OAAOzE,IAAM0E,cAAc5E,GAAMuE,GC7H1C,IAYeM,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,8BAAqBlE,MAAK,YAAkD,IAA/CmE,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,OCDdJ,IAASC,OACP,cAAC,IAAMU,WAAP,UACE,cAAC,EAAD,MAEFb,SAASc,eAAe,SAM1BT,M","file":"static/js/main.1705f561.chunk.js","sourcesContent":["import React, { useRef, useEffect, useState  } from \"react\";\nimport ReactDOM from \"react-dom\";\n\nimport * as cocoSsd from \"@tensorflow-models/coco-ssd\";\nimport \"@tensorflow/tfjs\";\n\n\nclass App extends React.Component {\n  // reference to both the video and canvas\n  videoRef = React.createRef();\n  canvasRef = React.createRef();\n\n  // we are gonna use inline style\n  styles = {\n    position: 'fixed',\n    top: 150,\n    left: 150,\n  };\n\n\n  detectFromVideoFrame = (model, video) => {\n    model.detect(video).then(predictions => {\n      this.showDetections(predictions);\n\n      requestAnimationFrame(() => {\n        this.detectFromVideoFrame(model, video);\n      });\n    }, (error) => {\n      console.log(\"Couldn't start the webcam\")\n      console.error(error)\n    });\n  };\n\n  showDetections = predictions => {\n    const ctx = this.canvasRef.current.getContext(\"2d\");\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\n    const font = \"24px helvetica\";\n    ctx.font = font;\n    ctx.textBaseline = \"top\";\n\n    predictions.forEach(prediction => {\n      const x = prediction.bbox[0];\n      const y = prediction.bbox[1];\n      const width = prediction.bbox[2];\n      const height = prediction.bbox[3];\n      // Draw the bounding box.\n      ctx.strokeStyle = \"#2fff00\";\n      ctx.lineWidth = 1;\n      ctx.strokeRect(x, y, width, height);\n      // Draw the label background.\n      ctx.fillStyle = \"#2fff00\";\n      const textWidth = ctx.measureText(prediction.class).width;\n      const textHeight = parseInt(font, 10);\n      // draw top left rectangle\n      ctx.fillRect(x, y, textWidth + 10, textHeight + 10);\n      // draw bottom left rectangle\n      ctx.fillRect(x, y + height - textHeight, textWidth + 15, textHeight + 10);\n\n      // Draw the text last to ensure it's on top.\n      ctx.fillStyle = \"#000000\";\n      ctx.fillText(prediction.class, x, y);\n      ctx.fillText(prediction.score.toFixed(2), x, y + height - textHeight);\n    });\n  };\n\n  componentDidMount() {\n    if (navigator.mediaDevices.getUserMedia || navigator.mediaDevices.webkitGetUserMedia) {\n      // define a Promise that'll be used to load the webcam and read its frames\n      const webcamPromise = navigator.mediaDevices\n        .getUserMedia({\n          video: true,\n          audio: false,\n        })\n        .then(stream => {\n          // pass the current frame to the window.stream\n          window.stream = stream;\n          // pass the stream to the videoRef\n          this.videoRef.current.srcObject = stream;\n\n          return new Promise(resolve => {\n            this.videoRef.current.onloadedmetadata = () => {\n              resolve();\n            };\n          });\n        }, (error) => {\n          console.log(\"Couldn't start the webcam\")\n          console.error(error)\n        });\n\n      // define a Promise that'll be used to load the model\n      const loadlModelPromise = cocoSsd.load();\n      \n      // resolve all the Promises\n      Promise.all([loadlModelPromise, webcamPromise])\n        .then(values => {\n          this.detectFromVideoFrame(values[0], this.videoRef.current);\n        })\n        .catch(error => {\n          console.error(error);\n        });\n    }\n  }\n\n  // here we are returning the video frame and canvas to draw,\n  // so we are in someway drawing our video \"on the go\"\n  render() {\n    return (\n      <div> \n        <video\n          style={this.styles}\n          autoPlay\n          muted\n          playsInline\n          ref={this.videoRef}\n          width=\"720\"\n          height=\"600\"\n        />\n        <canvas style={this.styles} ref={this.canvasRef} width=\"720\" height=\"650\" />\n      </div>\n    );\n  }\n}\n\nexport default App;\nconst domContainer = document.querySelector('#root');\nReactDOM.render(React.createElement(App), domContainer);\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}